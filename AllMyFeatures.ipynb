{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412fe1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from functools import partial\n",
    "import re\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from string import punctuation\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20ee57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pairs = pd.read_parquet(\"./hackathon_files_for_participants_ozon/fake_ontrain.parquet\")\n",
    "train_pairs = pd.read_parquet(\"./hackathon_files_for_participants_ozon/train_pairs_after_split_v2.parquet\")\n",
    "# train_pairs = pd.read_parquet(\"./hackathon_files_for_participants_ozon/syntetic_pos_neg_bad_cats.parquet\")\n",
    "train_pairs['variantid1'] = train_pairs['variantid1'].apply(str)\n",
    "train_pairs['variantid2'] = train_pairs['variantid2'].apply(str)\n",
    "data = pd.read_parquet(\"./hackathon_files_for_participants_ozon/train_data.parquet\")\n",
    "data['variantid'] = data['variantid'].apply(str)\n",
    "val_pairs = pd.read_parquet(\"./hackathon_files_for_participants_ozon/val_pairs_v2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0455b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = (\n",
    "    train_pairs\n",
    "    .merge(\n",
    "        data\n",
    "        .add_suffix('1'),\n",
    "        on=\"variantid1\",\n",
    "        how='inner'\n",
    "    )\n",
    "    .merge(\n",
    "        data\n",
    "        .add_suffix('2'),\n",
    "        on=\"variantid2\",\n",
    "        how='inner'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b22d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features = (\n",
    "    val_pairs\n",
    "    .merge(\n",
    "        data\n",
    "        .add_suffix('1'),\n",
    "        on=\"variantid1\",\n",
    "        how='inner'\n",
    "    )\n",
    "    .merge(\n",
    "        data\n",
    "        .add_suffix('2'),\n",
    "        on=\"variantid2\",\n",
    "        how='inner'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2c4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = pd.read_parquet(\"./hackathon_files_for_participants_ozon/test_pairs_wo_target.parquet\")\n",
    "# test_pairs = pd.read_parquet(\"./hackathon_files_for_participants_ozon/fake_ontrain.parquet\")\n",
    "test_pairs['variantid1'] = test_pairs['variantid1'].apply(str)\n",
    "test_pairs['variantid2'] = test_pairs['variantid2'].apply(str)\n",
    "test_data = pd.read_parquet(\"./hackathon_files_for_participants_ozon/test_data.parquet\")\n",
    "# test_data = pd.read_parquet(\"./hackathon_files_for_participants_ozon/train_data.parquet\")\n",
    "test_data['variantid'] = test_data['variantid'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd650448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variantid1</th>\n",
       "      <th>variantid2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52076340</td>\n",
       "      <td>290590137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64525522</td>\n",
       "      <td>204128919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77243372</td>\n",
       "      <td>479860557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86065820</td>\n",
       "      <td>540678372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91566575</td>\n",
       "      <td>258840506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variantid1 variantid2\n",
       "0   52076340  290590137\n",
       "1   64525522  204128919\n",
       "2   77243372  479860557\n",
       "3   86065820  540678372\n",
       "4   91566575  258840506"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa79cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = (\n",
    "    test_pairs\n",
    "    .merge(\n",
    "        test_data\n",
    "        .add_suffix('1'),\n",
    "        on=\"variantid1\",\n",
    "        how='inner'\n",
    "    )\n",
    "    .merge(\n",
    "        test_data\n",
    "        .add_suffix('2'),\n",
    "        on=\"variantid2\",\n",
    "        how='inner'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac3d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"../models/ru_roberta_base-sentence/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d30e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenizer(text, add_special_tokens=False).input_ids)\n",
    "    split_chr = chr(9601)\n",
    "    punct_set = set(',.?!*;|')\n",
    "    cur_words = []\n",
    "    cur_text = \"\"\n",
    "    for x in tokens:\n",
    "        if x.startswith(split_chr):\n",
    "            if len(cur_text) > 0:\n",
    "                cur_text = cur_text.replace(split_chr, '')\n",
    "                cur_text = cur_text[:-1] if cur_text[-1] in punct_set else cur_text\n",
    "                cur_words.append(cur_text)\n",
    "            cur_text = x\n",
    "        else:\n",
    "            cur_text += x\n",
    "    if len(cur_text) > 0:\n",
    "        cur_text = cur_text.replace(split_chr, '')\n",
    "        cur_text = cur_text[:-1] if cur_text[-1] in punct_set else cur_text\n",
    "        cur_words.append(cur_text)\n",
    "    return OrderedSet(cur_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aeb24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_name(name):\n",
    "    for_bert = []\n",
    "    for_fuzz = []\n",
    "    for n in tqdm(name, leave=False):\n",
    "        words = get_words(n)\n",
    "        f_b = []\n",
    "        f_f = []\n",
    "        for x in words:\n",
    "            if x.isalpha():\n",
    "                f_b.append(x)\n",
    "            else:\n",
    "                f_f.append(x)\n",
    "\n",
    "        for_bert.append(' '.join(f_b))\n",
    "        for_fuzz.append(' '.join(f_f))\n",
    "    return for_bert, for_fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b940d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dif(name1, name2):\n",
    "    name_diff1 = []\n",
    "    name_diff2 = []\n",
    "    for n1, n2 in tqdm(zip(name1, name2), total=len(name1), leave=False):\n",
    "        diff1 = get_words(n1)\n",
    "        diff2 = get_words(n2)\n",
    "        name_diff1.append(' '.join(diff1 - diff2))\n",
    "        name_diff2.append(' '.join(diff2 - diff1))\n",
    "    return name_diff1, name_diff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4549d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_features(arr, pos):\n",
    "    text = \"\"\n",
    "#     text += f\"Название: {arr[f'name{pos}']}\\n\"\n",
    "    \n",
    "#     d_dict = arr[f\"categories{pos}\"]\n",
    "#     if d_dict is not None:\n",
    "#         d_dict = eval(d_dict)\n",
    "#         text += f\"Категории: {', '.join(str(x) for x in d_dict.values())}\"\n",
    "#         for v in d_dict.values():\n",
    "#             text += str()\n",
    "#         text += '\\n'\n",
    "    d_dict = arr[f\"characteristic_attributes_mapping{pos}\"]\n",
    "    if d_dict is not None:\n",
    "        d_dict = eval(d_dict)\n",
    "        d_dict.pop('Партномер', None)\n",
    "        d_dict.pop('Комплектация', None)\n",
    "        d_dict.pop('Артикул', None)\n",
    "        d_dict.pop('Гарантийный срок', None)\n",
    "        d_dict.pop('Диапазон рабочей температуры', None)\n",
    "        d_dict.pop('Вариант', None)\n",
    "        text += \"Характеристики: \"\n",
    "        char_text = \"\"\n",
    "        for k, v in d_dict.items():\n",
    "            char_text += f\"{str(k)}: {','.join(str(x) for x in v)}; \"\n",
    "        text += char_text\n",
    "    else:\n",
    "        text += \"Характеристики: \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cffcf783",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['text_features1'] = test_features.apply(partial(create_text_features, pos='1'), axis=1)\n",
    "test_features['text_features2'] = test_features.apply(partial(create_text_features, pos='2'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a128d1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8727 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "a, b = add_dif(test_features['text_features1'].values, test_features['text_features2'].values)\n",
    "test_features['diff_text_characteristics_1'] = a\n",
    "test_features['diff_text_characteristics_2'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9253837",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['name_toked_1'] = test_features['name1'].apply(lambda x: list(get_words(x)))\n",
    "test_features['name_toked_2'] = test_features['name2'].apply(lambda x: list(get_words(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb62af74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a, b = split_name(test_features['name1'].values)\n",
    "test_features['clean_name_1'] = a\n",
    "test_features['service_name_1'] = b\n",
    "a, b = split_name(test_features['name2'].values)\n",
    "test_features['clean_name_2'] = a\n",
    "test_features['service_name_2'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d25d4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a, b = add_dif(test_features['name1'].values, test_features['name2'].values)\n",
    "test_features['diff_name_1'] = a\n",
    "test_features['diff_name_2'] = b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e04d6d",
   "metadata": {},
   "source": [
    "## With BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00eade96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(token_embeddings, att_mask):\n",
    "    input_mask_expanded = att_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdc55cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XLMRobertaModel.from_pretrained(\"../models/ru_roberta_base-sentence/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb9f93db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On GPU!\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.cuda(0)\n",
    "print(\"On GPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b6a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = torch.nn.CosineSimilarity(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dcb9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs(texts):\n",
    "    BS = 512 * 2\n",
    "    embs = []\n",
    "    for pos in tqdm(range(0, len(texts), BS), leave=False):\n",
    "        toked = tokenizer(texts[pos:pos+BS], truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        with torch.set_grad_enabled(False), torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):\n",
    "            emb = model(**toked.to('cuda:0')).last_hidden_state.cpu()\n",
    "            emb = mean_pooling(emb, toked.attention_mask.cpu())\n",
    "        embs.append(emb)\n",
    "    return torch.cat(embs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be5d2093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs1 = get_embs(test_features['clean_name_1'].values.tolist())\n",
    "embs2 = get_embs(test_features['clean_name_2'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82fd9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['bert_clean_name'] = cosine(embs1, embs2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3781d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs1 = get_embs(test_features['diff_name_1'].values.tolist())\n",
    "embs2 = get_embs(test_features['diff_name_2'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bb12fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['bert_diff_name'] = cosine(embs1, embs2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79df11b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs1 = get_embs(test_features['diff_text_characteristics_1'].values.tolist())\n",
    "embs2 = get_embs(test_features['diff_text_characteristics_2'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11d8e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['bert_diff_characteristics'] = cosine(embs1, embs2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999af08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88d4b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.to_parquet(\"./hackathon_files_for_participants_ozon/test_data_characteristics_diff_v1.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_parquet(\"./hackathon_files_for_participants_ozon/test_data_characteristics_diff_v1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2119cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features[[\n",
    "    'variantid1', 'variantid2', 'clean_name_1', 'service_name_1',\n",
    "    'clean_name_2', 'service_name_2', 'diff_name_1', 'diff_name_2',\n",
    "    'bert_clean_name', 'bert_diff_name', 'name_toked_1', 'name_toked_2',\n",
    "    'diff_text_characteristics_1', 'diff_text_characteristics_2',\n",
    "    'bert_diff_characteristics'\n",
    "]].to_parquet(\"./hackathon_files_for_participants_ozon/syntetic_pos_neg_bad_cats_names_smart_tok_bert_cosine+characteristics.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c8e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efdcc947",
   "metadata": {},
   "source": [
    "## Aggregating all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "141f5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_diff_characteristics = pd.read_parquet(\"./hackathon_files_for_participants_ozon/data_characteristics_diff_v1.parquet\")\n",
    "data_diff_names_bert = pd.read_parquet(\"./hackathon_files_for_participants_ozon/data_names_smart_tok_bert_cosine.parquet\")\n",
    "train_data_bm25 = pd.read_parquet(\"./hackathon_files_for_participants_ozon/train_data_bm25_name+characteristics.parquet\")\n",
    "val_data_bm25 = pd.read_parquet(\"./hackathon_files_for_participants_ozon/val_data_bm25_name+characteristics.parquet\")\n",
    "data_bm_25 = pd.concat([train_data_bm25, val_data_bm25], axis=0)\n",
    "data = pd.merge(data_diff_characteristics, data_diff_names_bert, how='inner', on=['variantid1', 'variantid2'])\n",
    "data = pd.merge(data, data_bm_25, how='inner', on=['variantid1', 'variantid2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e64e5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(\"./hackathon_files_for_participants_ozon/data_names_smart_tok_bert_diff_characteristics_bm25_char.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b2ccb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_bm25 = pd.read_parquet(\"./hackathon_files_for_participants_ozon/test_data_bm25_name+characteristics.parquet\")\n",
    "test_data_diff_characteristics = pd.read_parquet(\"./hackathon_files_for_participants_ozon/test_data_characteristics_diff_v1.parquet\")\n",
    "test_data_diff_names_bert = pd.read_parquet(\"./hackathon_files_for_participants_ozon/test_data_names_smart_tok_bert_cosine.parquet\")\n",
    "test_data = pd.merge(test_data_bm25, test_data_diff_characteristics, how='inner', on=['variantid1', 'variantid2'])\n",
    "test_data = pd.merge(test_data, test_data_diff_names_bert, how='inner', on=['variantid1', 'variantid2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d813efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data.to_parquet(\"./hackathon_files_for_participants_ozon/test_data_names_smart_tok_bert_diff_characteristics_bm25_char.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd144ea",
   "metadata": {},
   "source": [
    "## Bert Sim of intersection attributes and sim of non-intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf579df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_attributes_features(df):\n",
    "    first_attrs = df[f\"characteristic_attributes_mapping1\"].values\n",
    "    second_attrs = df[f\"characteristic_attributes_mapping2\"].values\n",
    "    res = []\n",
    "    non_intersections_1 = []\n",
    "    non_intersections_2 = []\n",
    "    intersections_1 = []\n",
    "    intersections_2 = []\n",
    "    intersections_small_1 = []\n",
    "    intersections_small_2 = []\n",
    "    lengths = []\n",
    "    ids = []\n",
    "    for id1, id2, d1, d2 in tqdm(zip(df['variantid1'].values, df['variantid2'].values, first_attrs, second_attrs), total=len(df)):\n",
    "        if d1 is not None and d2 is not None:\n",
    "            d1 = eval(d1)\n",
    "            d2 = eval(d2)\n",
    "            non_intersection_1 = {}\n",
    "            non_intersection_2 = {}\n",
    "            intersection_1 = {}\n",
    "            intersection_2 = {}\n",
    "            for k in d1.keys():\n",
    "                if k in d2:\n",
    "                    intersection_1[k] = d1[k]\n",
    "                    intersection_2[k] = d2[k]\n",
    "                else:\n",
    "                    non_intersection_1[k] = d1[k]\n",
    "            \n",
    "            for k in d2.keys():\n",
    "                if k not in d2:\n",
    "                    non_intersection_2[k] = d2[k]\n",
    "                    \n",
    "            non_intersection_1 = ';'.join(f\"{k}: {v} \" for k, v in non_intersection_1.items())\n",
    "            non_intersection_2 = ';'.join(f\"{k}: {v} \" for k, v in non_intersection_2.items())\n",
    "            non_intersections_1.append(non_intersection_1)\n",
    "            non_intersections_2.append(non_intersection_2)\n",
    "#             non_intersection_score = cosine(get_embs([non_intersection_1]), get_embs([non_intersection_2]))\n",
    "            \n",
    "            int_1 = ';'.join(f\"{k}: {v} \" for k, v in intersection_1.items())\n",
    "            int_2 = ';'.join(f\"{k}: {v} \" for k, v in intersection_2.items())\n",
    "            intersections_1.append(int_1)\n",
    "            intersections_2.append(int_2)\n",
    "            \n",
    "#             intersection_score = cosine(get_embs([int_1]), get_embs([int_2]))\n",
    "            \n",
    "            int_1, int_2 = [], []\n",
    "            for k in intersection_1.keys():\n",
    "                int_1.append(f\"{k}: {intersection_1[k]}\")\n",
    "                int_2.append(f\"{k}: {intersection_2[k]}\")\n",
    "            intersections_small_1 += int_1\n",
    "            intersections_small_2 += int_2\n",
    "            lengths.append(len(int_1))\n",
    "            ids.append((id1, id2))\n",
    "#             intersections = cosine(get_embs(int_1), get_embs(int_2))\n",
    "            \n",
    "#             res.append({\n",
    "#                 'intersection_score': intersection_score,\n",
    "#                 'non_intersection_score': non_intersection_score,\n",
    "#                 'intersection_mean': intersections.mean().item(),\n",
    "#                 'intersection_max': intersections.max().item(),\n",
    "#                 'intersection_min': intersections.min().item(),\n",
    "#                 'intersection_sum': intersections.sum().item(),\n",
    "#             })\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    non_intersection_score = cosine(get_embs(non_intersections_1), get_embs(non_intersections_2))\n",
    "    intersection_score = cosine(get_embs(intersections_1), get_embs(intersections_2))\n",
    "    \n",
    "#     intersection_score_small = cosine(get_embs(intersections_small_1), get_embs(intersections_small_2))\n",
    "    \n",
    "    pos = 0\n",
    "    for n_i, i, l, (id1, id2) in zip(non_intersection_score, intersection_score, lengths, ids):\n",
    "#         intersections = intersection_score_small[pos:pos+l]\n",
    "        res.append({\n",
    "            'variantid1': id1,\n",
    "            'variantid2': id2,\n",
    "            'intersection_score': i,\n",
    "            'non_intersection_score': n_i,\n",
    "#             'intersection_mean': intersections.mean().item(),\n",
    "#             'intersection_max': intersections.max().item(),\n",
    "#             'intersection_min': intersections.min().item(),\n",
    "#             'intersection_sum': intersections.sum().item(),\n",
    "        })\n",
    "        pos += l\n",
    "    \n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "670ca94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3847ca241c841fa98167c690257ec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18084 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_attr_feats_2 = creating_attributes_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5394b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_attr_feats_2 = creating_attributes_features(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de01f91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4970cf372ff04cc080620faa026a9da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_attr_feats_2 = creating_attributes_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23a294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db92c3bdc787404ea6acc11e8a47ec1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286331 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360d438f905d4bc5ab0cb77fc684305e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_attr_feats = creating_attributes_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39492abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attr_feats_2['intersection_score'] = test_attr_feats_2['intersection_score'].apply(lambda x: x.item())\n",
    "test_attr_feats_2['non_intersection_score'] = test_attr_feats_2['non_intersection_score'].apply(lambda x: x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5918b3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variantid1</th>\n",
       "      <th>variantid2</th>\n",
       "      <th>intersection_score</th>\n",
       "      <th>non_intersection_score</th>\n",
       "      <th>intersection_mean</th>\n",
       "      <th>intersection_max</th>\n",
       "      <th>intersection_min</th>\n",
       "      <th>intersection_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78292644</td>\n",
       "      <td>311184051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78509805</td>\n",
       "      <td>90849346</td>\n",
       "      <td>0.995929</td>\n",
       "      <td>0.542670</td>\n",
       "      <td>0.937880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.480445</td>\n",
       "      <td>32.825794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89722250</td>\n",
       "      <td>177811799</td>\n",
       "      <td>0.855937</td>\n",
       "      <td>0.553346</td>\n",
       "      <td>0.829601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.488802</td>\n",
       "      <td>2.488802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91147277</td>\n",
       "      <td>473287073</td>\n",
       "      <td>0.985562</td>\n",
       "      <td>0.522836</td>\n",
       "      <td>0.897102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>23.324646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91630181</td>\n",
       "      <td>388828373</td>\n",
       "      <td>0.982966</td>\n",
       "      <td>0.542459</td>\n",
       "      <td>0.937011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>7.496090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variantid1 variantid2  intersection_score  non_intersection_score  \\\n",
       "0   78292644  311184051            1.000000                0.603996   \n",
       "1   78509805   90849346            0.995929                0.542670   \n",
       "2   89722250  177811799            0.855937                0.553346   \n",
       "3   91147277  473287073            0.985562                0.522836   \n",
       "4   91630181  388828373            0.982966                0.542459   \n",
       "\n",
       "   intersection_mean  intersection_max  intersection_min  intersection_sum  \n",
       "0           1.000000               1.0          1.000000          3.000000  \n",
       "1           0.937880               1.0          0.480445         32.825794  \n",
       "2           0.829601               1.0          0.488802          2.488802  \n",
       "3           0.897102               1.0          0.351171         23.324646  \n",
       "4           0.937011               1.0          0.496090          7.496090  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_attr_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcdaea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_attr_feats_2.to_parquet(\"./hackathon_files_for_participants_ozon/test_data_inter_non_inter_scores.parquet\", engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18d3b1",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37081904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_scores = []\n",
    "for x, y in tqdm(train_features[['text_features1', 'text_features2']].values):\n",
    "    bm25 = BM25Okapi([list(get_words(x.lower()))])\n",
    "    bm25_scores.append(bm25.get_scores(list(get_words(y.lower())))[0])\n",
    "train_features['bm25_smart_tok'] = bm25_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ddad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_scores = []\n",
    "for x, y in tqdm(val_features[['text_features1', 'text_features2']].values):\n",
    "    bm25 = BM25Okapi([list(get_words(x.lower()))])\n",
    "    bm25_scores.append(bm25.get_scores(list(get_words(y.lower())))[0])\n",
    "val_features['bm25_smart_tok'] = bm25_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_scores = []\n",
    "for x, y in tqdm(test_features[['text_features1', 'text_features2']].values):\n",
    "    bm25 = BM25Okapi([list(get_words(x.lower()))])\n",
    "    bm25_scores.append(bm25.get_scores(list(get_words(y.lower())))[0])\n",
    "test_features['bm25_smart_tok'] = bm25_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d035c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f95b077c",
   "metadata": {},
   "source": [
    "## Getting positives and negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = train_pairs[train_pairs.target == 1]\n",
    "train_neg = train_pairs[train_pairs.target == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2id_pos = {}\n",
    "for id1, id2 in train_pos[['variantid1', 'variantid2']].values:\n",
    "    if id1 in id2id_pos:\n",
    "        id2id_pos[id1].add(id2)\n",
    "    else:\n",
    "        id2id_pos[id1] = set([id2])\n",
    "    if id2 in id2id_pos:\n",
    "        id2id_pos[id2].add(id1)\n",
    "    else:\n",
    "        id2id_pos[id2] = set([id1])\n",
    "id2id_neg = {}\n",
    "for id1, id2 in train_neg[['variantid1', 'variantid2']].values:\n",
    "    if id1 in id2id_neg:\n",
    "        id2id_neg[id1].add(id2)\n",
    "    else:\n",
    "        id2id_neg[id1] = set([id2])\n",
    "    if id2 in id2id_neg:\n",
    "        id2id_neg[id2].add(id1)\n",
    "    else:\n",
    "        id2id_neg[id2] = set([id1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf69854",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2id_pos_ = deepcopy(id2id_pos)\n",
    "id2id_neg_ = deepcopy(id2id_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id1 in tqdm(id2id_pos_.keys()):\n",
    "    cur_set = list(id2id_pos_[id1])\n",
    "    for id2 in cur_set:\n",
    "        id2id_pos_[id1].update(id2id_pos_[id2])\n",
    "for id1 in tqdm(id2id_pos_.keys()):\n",
    "    cur_set_pos = list(id2id_pos_[id1])\n",
    "    for id2 in cur_set_pos:\n",
    "        if id2 not in id2id_neg_:\n",
    "            continue\n",
    "        if id1 in id2id_neg_:\n",
    "            id2id_neg_[id1].update(id2id_neg_[id2])\n",
    "        else:\n",
    "            id2id_neg_[id1] = id2id_neg_[id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pairs_pos = set()\n",
    "for id1 in tqdm(id2id_pos_.keys()):\n",
    "    new_pairs_pos.update([tuple(sorted([id1, x])) for x in id2id_pos_[id1] if x != id1])\n",
    "new_pairs_neg = set()\n",
    "for id1 in tqdm(id2id_neg_.keys()):\n",
    "    new_pairs_neg.update([tuple(sorted([id1, x])) for x in id2id_neg_[id1] if x != id1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_pairs_pos = set([tuple(sorted([x, y])) for x, y in train_pos[['variantid1', 'variantid2']].values] +\n",
    "                 [tuple(sorted([y, x])) for x, y in train_pos[['variantid1', 'variantid2']].values])\n",
    "old_pairs_neg = set([tuple(sorted([x, y])) for x, y in train_neg[['variantid1', 'variantid2']].values] +\n",
    "                 [tuple(sorted([y, x])) for x, y in train_neg[['variantid1', 'variantid2']].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1209ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pairs_pos = new_pairs_pos - old_pairs_pos\n",
    "new_pairs_neg = new_pairs_neg - old_pairs_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63129d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pairs_pos = pd.DataFrame(list(new_pairs_pos), columns=['variantid1', 'variantid2'])\n",
    "new_pairs_pos['target'] = 1\n",
    "new_pairs_neg = pd.DataFrame(list(new_pairs_neg), columns=['variantid1', 'variantid2'])\n",
    "new_pairs_neg['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590eb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pairs_pos_features = (\n",
    "    new_pairs_pos\n",
    "    .merge(\n",
    "        data[['variantid', 'name', 'cat3']]\n",
    "        .add_suffix('1'),\n",
    "        on=\"variantid1\",\n",
    "        how='inner'\n",
    "    )\n",
    "    .merge(\n",
    "        data[['variantid', 'name', 'cat3']]\n",
    "        .add_suffix('2'),\n",
    "        on=\"variantid2\",\n",
    "        how='inner'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pairs_neg_features = (\n",
    "    new_pairs_neg\n",
    "    .merge(\n",
    "        data[['variantid', 'name', 'cat3']]\n",
    "        .add_suffix('1'),\n",
    "        on=\"variantid1\",\n",
    "        how='inner'\n",
    "    )\n",
    "    .merge(\n",
    "        data[['variantid', 'name', 'cat3']]\n",
    "        .add_suffix('2'),\n",
    "        on=\"variantid2\",\n",
    "        how='inner'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_bad_cats = set([\n",
    "    'Видеокарты и графические ускорители',\n",
    "    'Запчасти для ноутбуков',\n",
    "    'Мониторы и запчасти',\n",
    "    'Чехол',\n",
    "    'Оперативная память',\n",
    "    'Компьютер',\n",
    "    'Электронные модули',\n",
    "    'Сетевые фильтры, разветвители и удлинители',\n",
    "    'Системы охлаждения для компьютеров'\n",
    "])\n",
    "\n",
    "bad_cat = set(['Защитные пленки и стекла', 'Запчасти для аудио/видеотехники'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18745a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_pos = (new_pairs_pos_features['cat31'] == new_pairs_pos_features['cat32']) &\\\n",
    "    (new_pairs_pos_features['cat31'].isin(important_bad_cats) | new_pairs_pos_features['cat31'].isin(bad_cat))\n",
    "\n",
    "mask_neg = (new_pairs_neg_features['cat31'] == new_pairs_neg_features['cat32']) &\\\n",
    "    (new_pairs_neg_features['name1'] == new_pairs_neg_features['name2']) &\\\n",
    "    (new_pairs_neg_features['cat31'].isin(important_bad_cats) | new_pairs_neg_features['cat31'].isin(bad_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_positives_bad_cats = new_pairs_pos_features[mask_pos]\n",
    "new_negatives_bad_cats = new_pairs_neg_features[mask_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([new_negatives_bad_cats, new_positives_bad_cats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16273f2",
   "metadata": {},
   "source": [
    "## TRAIN/VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6decd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = pd.read_parquet(\"./hackathon_files_for_participants_ozon/train_pairs.parquet\")\n",
    "train_pairs['variantid1'] = train_pairs['variantid1'].apply(str)\n",
    "train_pairs['variantid2'] = train_pairs['variantid2'].apply(str)\n",
    "train_data = pd.read_parquet(\"./hackathon_files_for_participants_ozon/train_data.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"cat3\"] = train_data[\"categories\"].apply(lambda x: json.loads(x)[\"3\"])\n",
    "train_data['variantid'] = train_data['variantid'].apply(str)\n",
    "cat3_counts = train_data[\"cat3\"].value_counts().to_dict()\n",
    "cat2id = {k: i for i, k in enumerate(cat3_counts.keys())}\n",
    "train_data[\"cat3_grouped\"] = train_data[\"cat3\"].apply(lambda x: cat2id[x] if cat3_counts[x] > 1000 else len(cat2id))\n",
    "id2cat = {k : v for v, k in cat2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8498fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = train_pairs.merge(\n",
    "        train_data[['variantid', 'cat3']]\n",
    "        .add_suffix('1'),\n",
    "        on=\"variantid1\",\n",
    "        how='inner'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = pd.read_parquet(\"./hackathon_files_for_participants_ozon/test_pairs_wo_target.parquet\")\n",
    "test_pairs['variantid1'] = test_pairs['variantid1'].apply(str)\n",
    "test_pairs['variantid2'] = test_pairs['variantid2'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_example = pd.read_csv(\"./sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "must_have_groups = defaultdict(lambda: 0)\n",
    "for k, v in sub_example.cat3_grouped.value_counts().items():\n",
    "    if k == 'rest':\n",
    "        continue\n",
    "    must_have_groups[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_unseen(pairs, must_be_in_train, must_have_groups):\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    def find_examples(pairs, train_ids, val_ids):\n",
    "        train = []\n",
    "        val = []\n",
    "        for tgt, id1, id2, cat in pairs.values.tolist():\n",
    "            in_train1 = id1 in train_ids\n",
    "            in_train2 = id2 in train_ids\n",
    "            in_val1 = id1 in val_ids\n",
    "            in_val2 = id2 in val_ids\n",
    "            if in_train1 and in_val1:\n",
    "                raise RuntimeError(f\"First id both in train and in val!\")\n",
    "            elif in_train1 and in_val2:\n",
    "                raise RuntimeError(f\"First in train and second in val!\")\n",
    "            elif in_train2 and in_val1:\n",
    "                raise RuntimeError(f\"First in val and second in train!\")\n",
    "            elif in_train2 and in_val2:\n",
    "                raise RuntimeError(f\"Second id both in train and in val!\")\n",
    "            elif in_train1 or in_train2:\n",
    "                train.append((tgt, id1, id2))\n",
    "            elif in_val1 or in_val2:\n",
    "                val.append((tgt, id1, id2))\n",
    "            else:\n",
    "                raise RuntimeError(\"Unknown situation\")\n",
    "        return train, val\n",
    "    \n",
    "    def find_all_ids(cur_set):\n",
    "        tmp_set = set()\n",
    "        for x in cur_set:\n",
    "            tmp_set = tmp_set.union(id2id[x])\n",
    "            tmp_set.add(x)\n",
    "        to_add = len(tmp_set) - len(cur_set)\n",
    "        if to_add == 0:\n",
    "            return tmp_set\n",
    "        else:\n",
    "            return find_all_ids(tmp_set)\n",
    "    \n",
    "    cur_groups = defaultdict(lambda: np.inf, {k: 0 for k in must_have_groups.keys()})\n",
    "    id2group = {}\n",
    "    for id1, id2, cat in pairs[['variantid1', 'variantid2', 'cat31']].values:\n",
    "        if id1 not in id2group:\n",
    "            id2group[id1] = cat\n",
    "        if id2 not in id2group:\n",
    "            id2group[id2] = cat\n",
    "    \n",
    "    id2id = defaultdict(set)\n",
    "    all_ids = set()\n",
    "    for _, id1, id2, _ in pairs.values.tolist():\n",
    "        id2id[id1].add(id2)\n",
    "        id2id[id2].add(id1)\n",
    "        all_ids.update([id1, id2])\n",
    "    \n",
    "    train_ids = set()\n",
    "    val_ids = set()\n",
    "\n",
    "    while len(all_ids) > 0:\n",
    "        to_pop = set()\n",
    "        for x in all_ids:\n",
    "            to_pop.add(x)\n",
    "            break\n",
    "        to_pop = find_all_ids(to_pop)\n",
    "        for x in to_pop:\n",
    "            all_ids.remove(x)\n",
    "        if any(x in must_be_in_train for x in to_pop):\n",
    "            train_ids.update(to_pop)\n",
    "        else:\n",
    "            if any(cur_groups[id2group[x]] < must_have_groups[id2group[x]] for x in to_pop):\n",
    "                val_ids.update(to_pop)\n",
    "                for x in to_pop:\n",
    "                    cur_groups[id2group[x]] += 1\n",
    "            elif random.random() <= 0.06:\n",
    "                val_ids.update(to_pop)\n",
    "                for x in to_pop:\n",
    "                    cur_groups[id2group[x]] += 1\n",
    "            else:\n",
    "                train_ids.update(to_pop)\n",
    "    \n",
    "    return find_examples(pairs, train_ids, val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = set((x, y) for x, y in train_pairs[['variantid1', 'variantid2']].values.tolist())\n",
    "test_p = set((x, y) for x, y in test_pairs[['variantid1', 'variantid2']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34711850",
   "metadata": {},
   "outputs": [],
   "source": [
    "must_be_in_train = test_p.intersection(train_p)\n",
    "must_be_in_train = set(sum(must_be_in_train, ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = split_unseen(train_pairs, must_be_in_train, must_have_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ad721",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2group = {}\n",
    "for id1, id2, cat in train_pairs[['variantid1', 'variantid2', 'cat31']].values:\n",
    "    if id1 not in id2group:\n",
    "        id2group[id1] = cat\n",
    "    if id2 not in id2group:\n",
    "        id2group[id2] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2id = defaultdict(set)\n",
    "for _, id1, id2, _ in train_pairs.values.tolist():\n",
    "    id2id[id1].add(id2)\n",
    "    id2id[id2].add(id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b79cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs = pd.DataFrame(val, columns=['target', 'variantid1', 'variantid2'])\n",
    "train_pairs = pd.DataFrame(train, columns=['target', 'variantid1', 'variantid2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs['cat3'] = val_pairs.variantid1.apply(lambda x: id2group[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942604d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gr = {k: v for k, v in must_have_groups.items() if v > 0}\n",
    "cur_groups = {k: v for k, v in val_pairs.cat3.value_counts().items() if k in test_gr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_to_change = set()\n",
    "for id1, id2, cat in val_pairs[['variantid1', 'variantid2', 'cat3']].values:\n",
    "    if cat in cur_groups:\n",
    "        if cur_groups[cat] > must_have_groups[cat] + 400:\n",
    "            val_to_change.update([id1, id2])\n",
    "            cur_groups[cat] -= 1\n",
    "to_add = []\n",
    "for x in val_to_change:\n",
    "    to_add += list(id2id[x])\n",
    "val_to_change.update(to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (val_pairs.variantid1.isin(val_to_change) & val_pairs.variantid2.isin(val_to_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_pairs = val_pairs[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_pairs = pd.concat([train_pairs, val_pairs[mask][['target', 'variantid1', 'variantid2',]]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f993a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c74c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
